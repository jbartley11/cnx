{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get all data\n",
    "# convert time to dates\n",
    "# get unique users\n",
    "# get unique dates\n",
    "# iterate over each user and day\n",
    "# dbscan to id events\n",
    "# get user's name from worker fl\n",
    "# get center, start time, stop time, duration of each event\n",
    "# missing times\n",
    "# return to same site on same day\n",
    "# most traveled roads\n",
    "# analyze results\n",
    "# reduce smaller clusters to single points\n",
    "## snap to roads\n",
    "## create route\n",
    "## how much time, distance?\n",
    "## most efficient route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from arcgis.gis import GIS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "import pytz\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gis object\n",
    "password = getpass.getpass()\n",
    "gis = GIS(username = 'jason_cnx',\n",
    "          password = password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get layers needed\n",
    "tracks_id = \"619be0d131594c579132caf247802c15\"\n",
    "cluster_id = \"0af1d86ee5bf4bc3ac38849c3119a7d8\"\n",
    "\n",
    "# get tracks layer\n",
    "tracks_item = gis.content.get(tracks_id)\n",
    "tracks_layer = tracks_item.layers[0]\n",
    "\n",
    "# get cluster layer, for results\n",
    "cluster_item = gis.content.get(cluster_id)\n",
    "cluster_layer = cluster_item.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# query for all features\n",
    "track_features = tracks_layer.query(where=\"Creator = 'lss0wos_consol'\", out_fields=\"*\")\n",
    "# And CreationDate > '2018-10-12 00:00:00' And CreationDate < '2018-10-13 00:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert query featureset to spatially enabled dataframe\n",
    "# requires arcgis v1.5 or later\n",
    "df = track_features.sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set globalid as index\n",
    "# this will allow update of cluster field in main dataframe\n",
    "df.set_index('GlobalID', inplace=True, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add cluster column, with default value\n",
    "df[\"cluster\"] = -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert CreationDate to datetime\n",
    "df2['CreationDate'] = pd.to_datetime(df['CreationDate'], unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert timezone\n",
    "# TODO: confirm this matches what is on AGO\n",
    "utc = pytz.utc\n",
    "eastern = pytz.timezone('US/Eastern')\n",
    "\n",
    "def convert_timezone(date):\n",
    "    return utc.localize(date).astimezone(eastern)\n",
    "\n",
    "def convert_date(date):\n",
    "    return date.date()\n",
    "\n",
    "df2['dt_tz'] = df2['CreationDate'].apply(convert_timezone)\n",
    "df2['date_tz'] = df2['dt_tz'].apply(convert_date)\n",
    "# df2.head()\n",
    "\n",
    "# confirm dates look right\n",
    "# df2.groupby(\"date\")[\"date\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# populate fields for x and y\n",
    "def get_x(shape):\n",
    "    return shape['x']\n",
    "def get_y(shape):\n",
    "    return shape['y']\n",
    "\n",
    "df2['x'] = df2['SHAPE'].apply(get_x)\n",
    "df2['y'] = df2['SHAPE'].apply(get_y)\n",
    "# df2.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get unique dates and workers\n",
    "dates = np.unique(df2['date_tz'])\n",
    "workers = np.unique(df2['Creator'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eps = [30.48, 45.72, 60.96, 76.2, 91.44, 106.68, 121.92]   # unit: latitude/longitude 100-400\n",
    "min_sample = [5, 8, 12, 15, 18, 21]\n",
    "n1, n2 = len(eps), len(min_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get layers needed\n",
    "cluster_id = \"56923a29a9b443af9bbfb45c8702c075\"\n",
    "\n",
    "# get cluster layer, for results\n",
    "cluster_item = gis.content.get(cluster_id)\n",
    "cluster_layer = cluster_item.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get arrays of y, x\n",
    "X = df2[['y', 'x']].values\n",
    "\n",
    "for i in range(n1):\n",
    "    for j in range(n2):\n",
    "        \n",
    "\n",
    "        db = DBSCAN(eps=eps[i], min_samples=min_sample[j], metric=\"euclidean\").fit(X)\n",
    "\n",
    "        # count of arrays\n",
    "        clusters = np.unique(db.labels_)\n",
    "        cluster_count = (len(clusters) - 1)\n",
    "        print(cluster_count)\n",
    "        \n",
    "        # add cluster info to df3\n",
    "        df2['cluster'] = db.labels_.tolist()\n",
    "        \n",
    "        features = []\n",
    "        for index, row in df2.iterrows():\n",
    "            feature = {\"attributes\": \n",
    "                   {\"username\": row[\"Creator\"],\n",
    "                    \"capture_time\": row[\"CreationDate\"],\n",
    "                    \"original_globalid\": row[\"GlobalID\"],\n",
    "                    \"cluster\": row[\"cluster\"],\n",
    "                    \"eps\": eps[i],\n",
    "                    \"min_samples\": min_sample[j]}, \n",
    "                   \"geometry\": row['SHAPE']}\n",
    "            features.append(feature)\n",
    "            \n",
    "        add_result = cluster_layer.edit_features(adds = features)\n",
    "        print(add_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add cluster info to df3\n",
    "df2['cluster'] = db.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rename Creator to username\n",
    "# username, cluster, capture_time, capture_time_tz\n",
    "# original_globalid, eps, min_samples, capture_date_tz\n",
    "df3 = df2[['Creator', 'CreationDate', 'GlobalID', 'SHAPE', 'cluster',\n",
    "          'dt_tz', 'date_tz', 'eps', 'min_samples']]\n",
    "df3.columns = ['username', 'capture_time', 'original_globalid',\n",
    "               'SHAPE', 'cluster', 'capture_time_tz',\n",
    "               'capture_date_tz', 'eps', 'min_samples']\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#['username', 'capture_time', 'original_globalid',\n",
    "#               'SHAPE', 'cluster', 'capture_time_tz',\n",
    "#               'capture_date_tz', 'eps', 'min_samples']\n",
    "\n",
    "features = []\n",
    "for index, row in df3.iterrows():\n",
    "    feature = {\"attributes\": \n",
    "           {\"username\": row[\"username\"],\n",
    "            \"capture_time\": row[\"capture_time\"],\n",
    "            \"original_globalid\": row[\"original_globalid\"],\n",
    "            \"cluster\": row[\"cluster\"],\n",
    "            \"eps\": row[\"eps\"],\n",
    "            \"min_samples\": row[\"min_samples\"]}, \n",
    "           \"geometry\": row['SHAPE']}\n",
    "    features.append(feature)\n",
    "    \n",
    "    \n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_result = cluster_layer.edit_features(adds = features)\n",
    "add_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.reset_index(drop=True, inplace=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add fields for eps and min_samples\n",
    "df2['eps'] = 0.0\n",
    "df2['min_samples'] = 0\n",
    "df2.head()\n",
    "df2.spatial.to_featureclass(location=r\"/Users/jasonbartley/Development/python/cnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "inspect.getargspec(df2.spatial.to_featureclass)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.spatial.plot(map_widget= m1, renderer_type='u', col='cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_featurelayer(\"clustering_results\",gis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot x, y\n",
    "plt.scatter(df2['x'], df2['y'], c=df2['cluster'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = df2['cluster']\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.update(df3)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.groupby('cluster')['cluster'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter df2 by worker and date\n",
    "count = 0\n",
    "for worker in workers:\n",
    "    for date in dates:\n",
    "        print(date)\n",
    "        df3 = df2.loc[(df2['Creator'] == worker) & (df2['date_tz'] == date)]\n",
    "        \n",
    "        # get arrays of y, x\n",
    "        X = df3[['y', 'x']].values\n",
    "        db = DBSCAN(eps=91.44, min_samples=15, metric=\"euclidean\").fit(X)\n",
    "        \n",
    "        clusters = np.unique(db.labels_)\n",
    "        cluster_count = (len(clusters) - 1)\n",
    "        count += len(db.labels_)\n",
    "        print(cluster_count)\n",
    "\n",
    "        \n",
    "        # add cluster info to df3\n",
    "        df3['cluster'] = db.labels_.tolist()\n",
    "        print(df3.head())\n",
    "        \n",
    "        del df3\n",
    "        # get back into df2\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot x, y\n",
    "plt.scatter(df2['x'], df2['y'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get arrays of y, x\n",
    "X = df[['y', 'x']].values\n",
    "db = DBSCAN(eps=91.44, min_samples=15, metric=\"euclidean\").fit(X)\n",
    "np.unique(db.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add labels as new column in df\n",
    "df['cluster'] = db.labels_.tolist()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot x, y\n",
    "plt.scatter(df['x'], df['y'], c=df['cluster'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get min max of each cluster, creation date\n",
    "cluster_min_dt = df.groupby('cluster')['CreationDate'].min()\n",
    "cluster_max_dt = df.groupby('cluster')['CreationDate'].max()\n",
    "cluster_max_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "eps = [30.48, 45.72, 60.96, 76.2, 91.44, 106.68, 121.92]   # unit: latitude/longitude 100-400\n",
    "min_sample = [5, 8, 12, 15, 18, 21]\n",
    "n1, n2 = len(eps), len(min_sample)\n",
    "plt.subplots(nrows=n1, ncols=n2, figsize=(20, 15))\n",
    "ax.scatter(lons, lats, marker = 'o', color=color, edgecolor='gray', zorder=5, alpha=1.0, s=15)\n",
    "for i in range(n1):\n",
    "    for j in range(n2):\n",
    "        est = DBSCAN(eps=eps[i], min_samples=min_sample[j], metric=\"euclidean\").fit(X)\n",
    "        df2['oid'] = est.labels_.tolist()\n",
    "\n",
    "        ax = plt.subplot(n1, n2, n2*i+j+1)\n",
    "        ax.set_title(\"DBSCAN ('euclidean', eps={}, min_sample={})\".format(eps[i], min_sample[j]))\n",
    "        \n",
    "        # plot_stations_map(ax, works_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est1 = DBSCAN(eps=91.44, min_samples=15, metric=\"euclidean\").fit(X)\n",
    "np.unique(est1.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est1.core_sample_indices_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(est1.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_list = [x[0] for x in est1.components_]\n",
    "y_list\n",
    "x_list = [x[1] for x in est1.components_]\n",
    "len(x_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(x_list, y_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.to_featureclass(out_location=r\"C:\\Users\\jaso9356\\Desktop\\dev\\py\\cnx\\test.gdb\",\n",
    "                   out_name=\"df_test3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Log into ArcGIS anonymously\n",
    "g = GIS()\n",
    "# Retrieve an item from ArcGIS Online from a known ID value\n",
    "known_item = g.content.get(\"85d0ca4ea1ca4b9abf0c51b9bd34de2e\")\n",
    "known_item\n",
    "\n",
    "# Obtain the first feature layer from the item\n",
    "fl = known_item.layers[0]\n",
    "\n",
    "# Use the `from_layer` method of the Spatial DataFrame to create a new Spatial DataFrame\n",
    "sdf = SpatialDataFrame.from_layer(fl)\n",
    "\n",
    "# Return the first 5 records. \n",
    "sdf.head()\n",
    "\n",
    "\n",
    "sdf.to_featureclass(out_location=r\"path\\to\\your\\data\\output_example\",\n",
    "                   out_name=\"output_cities.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_stations_map(ax, stns):\n",
    "    # determine range to print based on min, max lat and lon of the data\n",
    "    lat = list(stns['y'])\n",
    "    lon = list(stns['x'])\n",
    "    margin = 0.01 # buffer to add to the range\n",
    "    lat_min = min(lat) - margin\n",
    "    lat_max = max(lat) + margin\n",
    "    lon_min = min(lon) - margin\n",
    "    lon_max = max(lon) + margin\n",
    "\n",
    "    # create map using BASEMAP\n",
    "    m = Basemap(llcrnrlon=lon_min,\n",
    "                llcrnrlat=lat_min,\n",
    "                urcrnrlon=lon_max,\n",
    "                urcrnrlat=lat_max,\n",
    "                lat_0=(lat_max - lat_min)/2,\n",
    "                lon_0=(lon_max - lon_min)/2,\n",
    "                projection='lcc',\n",
    "                resolution = 'f',)\n",
    "\n",
    "    m.drawcoastlines()\n",
    "    m.fillcontinents(lake_color='aqua')\n",
    "    m.drawmapboundary(fill_color='aqua')\n",
    "    m.drawrivers()    \n",
    "    \n",
    "    # plot points\n",
    "    clist = list(stns['cluster'].unique())\n",
    "    if -1 in clist:\n",
    "        clist.remove(-1)\n",
    "    k = len(clist)\n",
    "    colors = iter(cm.Set1(np.linspace(0, 1, max(10, k))))\n",
    "    for i in range(k):\n",
    "        color = next(colors)\n",
    "        df = stns.loc[stns['cluster'] == clist[i]]        \n",
    "        #print(\"Cluster {} has {} samples.\".format(clist[i], df.shape[0]))\n",
    "        \n",
    "        # convert lat and lon to map projection coordinates\n",
    "        lons, lats = m(list(df['station longitude']), list(df['station latitude']))        \n",
    "        ax.scatter(lons, lats, marker = 'o', color=color, edgecolor='gray', zorder=5, alpha=1.0, s=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
